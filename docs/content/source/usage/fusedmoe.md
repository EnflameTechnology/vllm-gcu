## fusedmoe
### 功能介绍

融合MoE性能提升：通过优化融合技术，使用混合专家（MoE）架构的模型性能得到了显著提升。这一更新增强了专家层计算的执行效率，减少了开销，并提高了利用大规模MoE模型的任务的吞吐量。

### 使用方法

该功能已默认使能，从用户角度不需要设置其他参数。