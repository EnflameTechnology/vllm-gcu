# ğŸ”¥ vLLM-GCU

> **vLLM-GCU** æ˜¯ç”±ç‡§åŸç§‘æŠ€åŸºäºåŸç”Ÿ [vLLM](https://github.com/vllm-project/vllm) æ¡†æ¶é€‚é… Enflame GCUï¼ˆS60ï¼‰æ¨å‡ºçš„å¤§æ¨¡å‹æ¨ç†ç³»ç»Ÿï¼Œæ”¯æŒå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åŠå¤šæ¨¡æ€è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„éƒ¨ç½²ä¸è¿è¡Œã€‚è¯¥é¡¹ç›®åœ¨ä¿ç•™ vLLM æ ¸å¿ƒè°ƒåº¦ç­–ç•¥ä¸è¿è¡Œæœºåˆ¶çš„åŸºç¡€ä¸Šï¼Œé’ˆå¯¹ GCU æ¶æ„å®ç°äº†é«˜æ•ˆçš„ç®—å­æ‰§è¡Œä¼˜åŒ–ã€‚

---

<p align="center">
  <a href="./ReadMe-EN.md">English</a> |
  <a href="./ReadMe.md">ç®€ä½“ä¸­æ–‡</a> |
</p>

## ğŸ“Œ ç‰¹æ€§ä¸€è§ˆ

* å®Œæ•´æ”¯æŒ **vLLM 0.8.0** åŠŸèƒ½ç‰¹æ€§
* é¢å‘ç‡§åŸç¬¬ä¸‰ä»£ **S60 GCU**ï¼Œæ·±åº¦ä¼˜åŒ–æ¨ç†æµç¨‹
* æ”¯æŒ FP16ã€BF16ï¼Œä»¥åŠ GPTQã€AWQã€INT8 ç­‰å¤šç§é‡åŒ–æ–¹å¼
* åŸç”Ÿæ”¯æŒ Qwenã€LLaMaã€Gemmaã€Mistralã€ChatGLMã€DeepSeek ç³»åˆ— LLMï¼ˆå’Œ/æˆ–VLMï¼‰æ¨ç†
* æä¾›æ€§èƒ½æµ‹è¯•ä¸æ‰¹é‡æ¨ç†å·¥å…·ï¼Œä¾¿äºéƒ¨ç½²ä¸è¯„ä¼°

---

## âš™ï¸ å®‰è£…æŒ‡å—

### ğŸ”§ ç³»ç»Ÿä¸ç¯å¢ƒè¦æ±‚

* **æ“ä½œç³»ç»Ÿ**: Ubuntu 20.04 / 22.04
* **Python**: 3.10 \~ 3.12
* **ç¡¬ä»¶**: ç‡§åŸ S60 GCUï¼ˆå·²éƒ¨ç½² TopsRider **i3x 3.4+** è½¯ä»¶æ ˆï¼‰

### ğŸ“¦ å®‰è£…æ­¥éª¤

#### 1ï¸âƒ£ å®‰è£…ä¾èµ–ç»„ä»¶ï¼ˆä¸»æœºç¯å¢ƒï¼‰

è¯·é¦–å…ˆå‚è€ƒ[ã€ŠTopsRider è½¯ä»¶æ ˆå®‰è£…æ‰‹å†Œã€‹](https://support.enflame-tech.com/onlinedoc_dev_3.4/2-install/sw_install/content/source/installation.html)åœ¨ä¸»æœºä¸­å®Œæˆ**é©±åŠ¨ç¨‹åº**å®‰è£…ã€‚


#### 2ï¸âƒ£ å®‰è£…æ–¹å¼ï¼ˆä»»é€‰å…¶ä¸€ï¼ŒDocker ç¯å¢ƒä¸­ï¼‰

**Python3.10+ï¼š** ç¡®ä¿ä½ å·²ç»å®‰è£…äº† Python 3.10 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼Œå¹¶ä¸”é»˜è®¤çš„ Python ç‰ˆæœ¬æ˜¯ 3.10 åŠä»¥ä¸Šã€‚

```bash
# æ£€æŸ¥é»˜è®¤çš„ python ç‰ˆæœ¬
python3 --version

# å¦‚æœé»˜è®¤çš„ python ç‰ˆæœ¬å°äº 3.10ï¼Œåˆ™å®‰è£… python3.10
sudo apt update && sudo apt install python3.10 -y

# å°†é»˜è®¤çš„ python ç‰ˆæœ¬åˆ‡æ¢ä¸º 3.10
sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1
sudo update-alternatives --config python3

# ä¸º python3.10 å®‰è£…pip
sudo apt update && sudo apt install python3.10-distutils -y
curl -sS https://bootstrap.pypa.io/get-pip.py | sudo python3

# å®‰è£…setuptools
python3 -m pip install setuptools
```

âœ… **æ–¹å¼ä¸€ï¼šä½¿ç”¨ TopsRider å®‰è£…**

```bash
python3 -m pip install triton==3.2
sudo chmod +x ./TopsRider_i3x_3.4.xxx.run
sudo ./TopsRider_i3x_3.4.xxx.run -y -C vllm-gcu
```

âœ… **æ–¹å¼äºŒï¼šä»æºä»£ç ç¼–è¯‘å¹¶å®‰è£… `.whl` åŒ…**

```bash
# å®‰è£…ä¾èµ–
python3 -m pip install torch==2.6.0+cpu -i https://download.pytorch.org/whl/cpu
python3 -m pip install torchvision==0.21.0 -i https://download.pytorch.org/whl/cpu
python3 -m pip install vllm==0.8.0
python3 -m pip install triton==3.2
# Enflameä¾èµ–
python3 -m pip install torch_gcu-2.6.0+<version>*.whl
python3 -m pip install tops_extension-<version>*.whl
python3 -m pip install xformers-<version>*.whl
sudo dpkg -i topsaten_3.4*.deb
sudo dpkg -i eccl_3.3*.deb
sudo apt install python3.10-dev -y #æ ¹æ®pythonç‰ˆæœ¬é€‰æ‹©

# ç¼–è¯‘ vllm_gcu .whlå®‰è£…åŒ…
python3 setup.py bdist_wheel

# å®‰è£…ç¼–è¯‘å¥½çš„ vllm_gcu whlåŒ…
python3 -m pip install ./dist/vllm_gcu-0.8.0+<version>*.whl
```

---

## ğŸš€ ä½¿ç”¨è¯´æ˜

### âœ… å¯åŠ¨æ¨ç†æ—¶å¿…å¤‡å‚æ•°

* å¯åŠ¨éœ€æŒ‡å®šï¼š`--device=gcu`
* ä»…æ”¯æŒ `xformers` ä½œä¸º attention backend
* é»˜è®¤å…³é—­ä»¥ä¸‹åŠŸèƒ½ï¼š

  * vLLM æ—¥å¿—ç»Ÿè®¡æ”¶é›†
  * Async output process åŠŸèƒ½
  * Fork å¯åŠ¨æ¨¡å¼ï¼ˆé»˜è®¤ä½¿ç”¨ `spawn`ï¼‰
  * è‡ªåŠ¨è¾“å…¥ dumpï¼ˆæ¨ç†å¤±è´¥æ—¶ï¼‰
* é•¿åºåˆ—é¢„å¡«å…… (`chunked-prefill`) é»˜è®¤å…³é—­ï¼ˆ>32Kï¼‰
* Top-p ç­‰åå¤„ç†ä½¿ç”¨åŸå§‹ç²¾åº¦è®¡ç®—

---

## ğŸ§  æ¨¡å‹é€‚é…æŒ‡å—

ğŸ“š vLLM-GCU å·²æ”¯æŒçš„æ¨¡å‹å‚è§`vLLM-GCU æ¨¡å‹æ”¯æŒåˆ—è¡¨`ï¼Œä»¥ä¸‹ä¸ºQwen2.5-32Bæ¨¡å‹æ¨ç†ä¸æ€§èƒ½æµ‹è¯•ç¤ºä¾‹ï¼Œå…¶å®ƒæ¨¡å‹ä¸æ­¤ç±»ä¼¼ï¼š

#### æ¨¡å‹ä¸‹è½½
*  Url: [Qwen2.5-32B-Instruct-GPTQ-Int8](https://www.modelscope.cn/models/Qwen/Qwen2.5-32B-Instruct-GPTQ-Int8/files)

*  branch: `master`

*  commit id: `996af7d8`

ä»ä¸Šè¿°Urlä¸‹è½½æ¨¡å‹åˆ°`Qwen2.5-32B-Instruct-GPTQ-Int8`æ–‡ä»¶å¤¹ä¸­ã€‚

#### æ‰¹é‡ç¦»çº¿æ¨ç†
```shell
python3 -m vllm_utils.benchmark_throughput \
 --model=[Qwen2.5-32B-Instruct-GPTQ-Int8æ–‡ä»¶å¤¹] \
 --tensor-parallel-size=2 \
 --max-model-len=32768 \
 --output-len=128 \
 --demo=te \
 --dtype=float16 \
 --device gcu \
 --quantization=gptq
```

#### Servingæ¨¡å¼

```shell
# å¯åŠ¨æœåŠ¡ç«¯
python3 -m vllm.entrypoints.openai.api_server \
 --model [Qwen2.5-32B-Instruct-GPTQ-Int8æ–‡ä»¶å¤¹] \
 --tensor-parallel-size 2 \
 --max-model-len 32768 \
 --disable-log-requests \
 --block-size=64 \
 --dtype=float16 \
 --device gcu \
 --trust-remote-code


# å¯åŠ¨å®¢æˆ·ç«¯
python3 -m vllm_utils.benchmark_serving \
 --backend vllm \
 --dataset-name random \
 --model [path of Qwen2.5-32B-Instruct-GPTQ-Int8] \
 --num-prompts 1 \
 --random-input-len 1024 \
 --random-output-len 1024 \
 --trust-remote-code \
 --ignore_eos \
 --strict-in-out-len \
 --keep-special-tokens
```

---

## ğŸ“Š æ€§èƒ½æµ‹è¯•ä¸ Benchmark å·¥å…·

### å·¥å…·è¯´æ˜

* ç¦»çº¿æ¨ç†ï¼šå±•ç¤º GCU å¹¶æ¨ç†èƒ½åŠ›
* æ€§èƒ½æµ‹è¯•ï¼šç»Ÿè®¡ TPS / TTFT / latency ç­‰æŒ‡æ ‡
* å¯åŠ¨æ–¹å¼ï¼š`vllm_utils.benchmark_throughput`

æŸ¥çœ‹å‚æ•°å¸®åŠ©ï¼š

```bash
python3 -m vllm_utils.benchmark_throughput --help
```

### æ¨ç†æµ‹è¯•å‚æ•°

| å‚æ•°åç§°                        | æè¿°                     |
| --------------------------- | ---------------------- |
| `--input-len`               | è¾“å…¥ token é•¿åº¦            |
| `--output-len`              | è¾“å‡º token é•¿åº¦            |
| `--num-prompts`             | è¯·æ±‚æ•°é‡                   |
| `--dtype`                   | æ•°æ®ç±»å‹ï¼ˆfloat16/bfloat16ï¼‰ |
| `--device`                  | å›ºå®šä¸º `gcu`              |
| `--tensor-parallel-size`    | å¹¶è¡Œå¼ é‡æ•°ï¼ˆå¤šå¡ï¼‰              |
| `--quantization`            | é‡åŒ–æ–¹å¼ï¼Œå¦‚ï¼šgptqã€awqã€w8a16  |
| `--kv-cache-dtype`          | KV ç¼“å­˜é‡åŒ–ç±»å‹ï¼Œå¦‚ï¼šint8       |
| `--quantization-param-path` | KV é‡åŒ–å‚æ•°æ–‡ä»¶è·¯å¾„            |

---

## ğŸ§© é‡åŒ–æ”¯æŒ

### âœ… å·²æ”¯æŒé‡åŒ–æ–¹æ³•

| æ–¹æ³•             | æè¿°                                               |
| -------------- | ------------------------------------------------ |
| `GPTQ`         | 4-bit group quantizationï¼Œæ”¯æŒ group-size ä¸º 64 æˆ–å…¶å€æ•° |
| `AWQ`          | æ”¯æŒ group-size 64                                 |
| `W8A16`        | æƒé‡é‡åŒ–ä¸º INT8ï¼Œæ¿€æ´»ä¸º FP16                              |
| `INT8 KVCache` | KV Cache æ”¯æŒ INT8 ç²¾åº¦å­˜å‚¨ï¼ˆéœ€é™„åŠ é…ç½®ï¼‰                     |

> âŒ æš‚ä¸æ”¯æŒï¼š`g_idx` ä¹±åºï¼ˆGPTQï¼‰ã€SqueezeLLMã€FP8ã€gptq\_marlin ç­‰

---

## ğŸ§ª vLLM-GCU æ¨¡å‹æ”¯æŒåˆ—è¡¨

| æ¨¡å‹åç§°                   | FP16 | BF16 | W4A16 GPTQ | W8A16 GPTQ | W4A16 AWQ | W8A16 | W8A8 INT8 | INT8 KV |
| ---------------------- | ---- | ---- | ---------- | ---------- | --------- | ----- | --------- | ------- |
| **Baichuan2**          | âœ…    | âœ…    | âœ…          | âœ…          | âœ…         | âœ…     | âœ…         | âœ…       |
| **ChatGLM3**           | âœ…    | âœ…    | âœ…          | âœ…          | âœ…         | âœ…     | âœ…         | âœ…       |
| **DBRX**               | âœ…    | âŒ    | âŒ          | âœ…          | âœ…         | âœ…     | âœ…         | âœ…       |
| **DeepSeek-V3/R1**        | âŒ    | âŒ    | âŒ          | âŒ          | âœ…         | âŒ     | âŒ         | âŒ       |
| **DeepSeek-Prover-V2** | âŒ    | âœ…    | âŒ          | âŒ          | âŒ         | âŒ     | âŒ         | âŒ       |
| **Gemma**              | âœ…    | âœ…    | âœ…          | âœ…          | âœ…         | âœ…     | âœ…         | âœ…       |
| **codegemma**          | âœ…    | âœ…    | âŒ          | âŒ          | âŒ         | âŒ     | âŒ         | âŒ       |
| **InternLM2**          | âœ…    | âœ…    | âœ…          | âœ…          | âœ…         | âœ…     | âœ…         | âœ…       |
| **LLaMA(2/3/3.1)**             | âœ…    | âœ…    | âœ…          | âœ…          | âœ…         | âœ…     | âœ…         | âœ…       |
| **Mixtral**            | âœ…    | âœ…    | âŒ          | âŒ          | âŒ         | âŒ     | âŒ         | âŒ       |
| **Qwen(1.5/2/2.5/3)**            | âœ…    | âœ…    | âœ…          | âœ…          | âœ…         | âœ…     | âœ…         | âœ…       |
| **Qwen3-MoE**          | âœ…    | âœ…    | âŒ          | âŒ          | âœ…         | âŒ     | âŒ         | âŒ       |
| **WizardCoder**        | âœ…    | âœ…    | âŒ          | âŒ          | âŒ         | âŒ     | âŒ         | âŒ       |
| **Yi**                 | âœ…    | âœ…    | âœ…          | âœ…          | âœ…         | âœ…     | âœ…         | âœ…       |
| **gte-Qwen2**          | âœ…    | âŒ    | âŒ          | âŒ          | âŒ         | âŒ     | âŒ         | âŒ       |
| **jina-reranker-v2**   | âŒ    | âœ…    | âŒ          | âŒ          | âŒ         | âŒ     | âŒ         | âŒ       |

---

## å›¾æ ‡è¯´æ˜ï¼š

* âœ…ï¼šå·²æ”¯æŒå¹¶éªŒè¯ï¼›
* âŒï¼šæš‚æœªæ”¯æŒæˆ–å°šæœªéªŒè¯ï¼›
* ç©ºç™½ï¼šæ— æ˜ç¡®ä¿¡æ¯æˆ–æœªå…¬å¼€æµ‹è¯•ç»“æœï¼›

---

## é™„åŠ è¯´æ˜ï¼š

1. **W4A16/W8A16 GPTQ / AWQ**ï¼šå‡ä¸º4bit/8bit æƒé‡é‡åŒ–ç®—æ³•ï¼Œæ¨¡å‹éœ€é€šè¿‡ Enflame TopsCompressor å·¥å…·é‡åŒ–ï¼›
2. **INT8ï¼ˆW8A8ï¼‰/ INT8 KV**ï¼šéœ€åŠ è½½é¢å¤–é‡åŒ–ç¼“å­˜é…ç½®æ–‡ä»¶ï¼ˆå¦‚ `int8_kv_cache.json`ï¼‰ï¼Œé€šå¸¸é€‚ç”¨äºæé™å‹ç¼©ä¸‹çš„æ¨ç†éƒ¨ç½²ï¼›
3. **æ”¯æŒæ¨¡å‹ä¸æ–­æ›´æ–°**ï¼Œå¦‚éœ€éªŒè¯ç‰¹å®šæ¨¡å‹ï¼Œå»ºè®®è”ç³»å®˜æ–¹è·å–æ”¯æŒæ¸…å•æˆ–æµ‹è¯•è¡¥ä¸ï¼›
4. **Qwen ç³»åˆ—æ”¯æŒæœ€å®Œå¤‡**ï¼Œæ¶µç›–å¤šä¸ªæ¨¡å‹å°ºå¯¸ã€é‡åŒ–æ ¼å¼å’Œæ¨ç†æ–¹å¼ï¼ˆåŒ…æ‹¬è§†è§‰è¯­è¨€æ¨¡å‹ï¼‰ï¼›

---

## ğŸŒ Serving æ¨¡å¼éƒ¨ç½²

æ”¯æŒå…¼å®¹ vLLM çš„ OpenAI API æ¥å£ï¼Œå¯å¿«é€Ÿé›†æˆè‡³ LangChain ç­‰åº”ç”¨ã€‚

### å¯åŠ¨æœåŠ¡ç«¯ï¼š

```bash
python3 -m vllm.entrypoints.openai.api_server \
 --model=[æ¨¡å‹è·¯å¾„] \
 --tensor-parallel-size=4 \
 --max-model-len=32768 \
 --gpu-memory-utilization=0.9 \
 --dtype=bfloat16 \
 --quantization-param-path=[é‡åŒ–è·¯å¾„] \
 --kv-cache-dtype=int8
```

### å¯åŠ¨å®¢æˆ·ç«¯ï¼š

```bash
python3 -m vllm_utils.benchmark_serving \
 --backend=vllm \
 --dataset-name=random \
 --model=[æ¨¡å‹è·¯å¾„] \
 --num-prompts=1 \
 --random-input-len=3000 \
 --random-output-len=1000
```

---

## ğŸ§ª sampler å‚æ•°æ‰©å±•ï¼ˆå·²æ”¯æŒï¼‰

| å‚æ•°                                                                  | åŠŸèƒ½è¯´æ˜               |
| ------------------------------------------------------------------- | ------------------ |
| `--top-p`, `--top-k`                                                | Top-k / Top-p é‡‡æ ·æ§åˆ¶ |
| `--presence-penalty`, `--frequency-penalty`, `--repetition-penalty` | æŠ‘åˆ¶é‡å¤æ€§è¾“å‡º            |
| `--ignore-eos`                                                      | å¿½ç•¥ EOS åç»§ç»­ç”Ÿæˆ       |
| `--include-stop-str-in-output`                                      | æ˜¯å¦åŒ…å«åœæ­¢å­—ç¬¦           |
| `--keep-special-tokens`                                             | æ˜¯å¦ä¿ç•™ç‰¹æ®Š token       |
| `--strict-in-out-len`                                               | å¼ºåˆ¶å›ºå®šè¾“å…¥/è¾“å‡ºé•¿åº¦        |

---

## ğŸ“š å‚è€ƒæ–‡æ¡£

* [vLLM å®˜æ–¹æ–‡æ¡£](https://docs.vllm.ai/en/v0.8.0/)
* [TopsRider å®‰è£…æ‰‹å†Œï¼ˆè”ç³» Enflame è·å–ï¼‰](https://www.enflame-tech.com/)
* [TopsCompressor é‡åŒ–å·¥å…·](https://egc.enflame-tech.com/)

---

## ğŸ“ è®¸å¯ä¿¡æ¯

æœ¬é¡¹ç›®éµå¾ª [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0)

---

ğŸ“§ æœ‰é—®é¢˜ï¼Ÿå»ºè®®æäº¤ Issue æˆ–è”ç³» [support@enflame-tech.com](mailto:support@enflame-tech.com)

ğŸ’¡ æƒ³äº†è§£æ›´å¤š Enflame GCU èƒ½åŠ›ï¼Ÿæ¬¢è¿è®¿é—® [å®˜ç½‘](https://www.enflame-tech.com/)
